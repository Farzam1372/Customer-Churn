# Customer-Churn-Prediction (Coursera Challenge)
# ğŸ¯ Customer Churn Prediction - Data Science Coding Challenge

Welcome to the **Customer Churn Prediction Challenge**, where we tackle one of the most industry-relevant machine learning problemsâ€”**predicting customer churn** for a **video streaming platform**.  

## ğŸš€ Challenge Overview
Subscription-based services are a **multi-billion dollar industry**, spanning fitness, streaming, and retail sectors. One of the key business objectives for these companies is **reducing churn**â€”ensuring that users remain **active subscribers**.  

### **ğŸ” The Task**
As a **data scientist** at a video streaming company, your goal is to **predict whether a user will continue their subscription next month** using **machine learning**.  

We use **customer activity, preferences, and subscription history** to train a model that can **detect potential churners**, allowing the company to **take action** before a user cancels.

---

## ğŸ“‚ Dataset Overview

The challenge provides **two datasets**:

| Dataset  | Description |
|----------|------------|
| **train.csv** | 243,787 subscriptions (70% of total) with the target column **Churn** (1 = churned, 0 = stayed) |
| **test.csv** | 104,480 subscriptions (30% of total) **without Churn labels** (your goal is to predict these) |

Each row represents **a unique customer subscription** at a snapshot in time.

### **ğŸ“ Features in the Data**
The dataset includes:
- `CustomerID` â€“ Unique identifier for each customer
- `AccountAge` â€“ How long the user has had an account
- `ViewingHoursPerWeek` â€“ Average time spent watching per week
- `ContentDownloadsPerMonth` â€“ Number of downloads per month
- `MonthlyCharges` â€“ Subscription fee
- `TotalCharges` â€“ Total amount spent
- `SupportTicketsPerMonth` â€“ Customer support interactions
- `WatchlistSize` â€“ Number of saved content items
- `UserRating` â€“ Customer satisfaction rating (1-5)
- **Target (`Churn`)** â€“ **(1 = Churned, 0 = Stayed) [Only in `train.csv`]**

---

## ğŸ† Model Approach

### **1ï¸âƒ£ Data Preprocessing**
âœ” **Handled missing values**  
âœ” **Converted categorical features using One-Hot Encoding**  
âœ” **Normalized numerical data (if needed)**  
âœ” **Checked for class imbalance & applied techniques like SMOTE if required**

### **2ï¸âƒ£ Model Selection**
After testing various models, we chose **Random Forest Classifier** because:
âœ” It handles categorical & numerical data efficiently  
âœ” It is robust against overfitting  
âœ” It provides **feature importance insights**  

### **3ï¸âƒ£ Hyperparameter Tuning**
We used **`GridSearchCV`** to optimize parameters like:
- `n_estimators` â†’ Number of trees
- `max_depth` â†’ Maximum depth of trees
- `min_samples_split` â†’ Minimum samples required to split a node
- `min_samples_leaf` â†’ Minimum samples per leaf

### **4ï¸âƒ£ Performance Evaluation**
âœ” **Trained the model on `train.csv`**  
âœ” **Tested on `X_test` and calculated AUC Score**  
âœ” **AUC Score Before Tuning: `0.7313`**  
âœ” **AUC Score After Tuning: `0.XXXX`** (Update based on results)

---

## ğŸ›  How to Run the Model

### **ğŸ”¹ Install Dependencies**
```bash
pip install -r requirements.txt

